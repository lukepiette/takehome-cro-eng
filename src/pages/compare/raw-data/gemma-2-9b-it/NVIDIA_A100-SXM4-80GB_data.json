[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.pco0so9xwK",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.017173029948026,
    "num_requests": 1,
    "output_throughput": 63.45514147752512,
    "requests_per_second": 0.495743292793165,
    "resource_usage": {
      "avg_cpu_usage": 0.7,
      "avg_gpu_memory_used": 35.441253662109375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 85,
    "timestamp": 1727308095,
    "tokens_per_second": 126.91028295505023,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.SSANhIU2t3",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.0219750890973955,
    "num_requests": 2,
    "output_throughput": 126.6088792984476,
    "requests_per_second": 0.9891318695191219,
    "resource_usage": {
      "avg_cpu_usage": 0.75,
      "avg_gpu_memory_used": 35.450042724609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 47,
    "timestamp": 1727308142,
    "tokens_per_second": 253.2177585968952,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.mwXDlZZrJ6",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.041639667004347,
    "num_requests": 4,
    "output_throughput": 250.77882658463741,
    "requests_per_second": 1.9592095826924798,
    "resource_usage": {
      "avg_cpu_usage": 0.3,
      "avg_gpu_memory_used": 35.456878662109375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 46,
    "timestamp": 1727308188,
    "tokens_per_second": 501.55765316927483,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.hvpkqmX8uM",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.1385932359844446,
    "num_requests": 8,
    "output_throughput": 478.81943268591175,
    "requests_per_second": 3.7407768178586855,
    "resource_usage": {
      "avg_cpu_usage": 0.1,
      "avg_gpu_memory_used": 35.471527099609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 48,
    "timestamp": 1727308236,
    "tokens_per_second": 957.6388653718235,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.6BG48rQIVU",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.3213825330603868,
    "num_requests": 16,
    "output_throughput": 882.2328809806396,
    "requests_per_second": 6.892444382661247,
    "resource_usage": {
      "avg_cpu_usage": 0.1,
      "avg_gpu_memory_used": 35.508636474609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 43,
    "timestamp": 1727308279,
    "tokens_per_second": 1764.4657619612792,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.TmJVdsVlJ5",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.678286600159481,
    "num_requests": 32,
    "output_throughput": 1529.33595671057,
    "requests_per_second": 11.947937161801327,
    "resource_usage": {
      "avg_cpu_usage": 0.45,
      "avg_gpu_memory_used": 35.570159912109375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 48,
    "timestamp": 1727308327,
    "tokens_per_second": 3058.67191342114,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.WRSIjTocCo",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.4575074380263686,
    "num_requests": 64,
    "output_throughput": 2369.336913032412,
    "requests_per_second": 18.51044463306572,
    "resource_usage": {
      "avg_cpu_usage": 0.4,
      "avg_gpu_memory_used": 35.723480224609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 53,
    "timestamp": 1727308380,
    "tokens_per_second": 4738.673826064824,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.hmWoi2cfVi",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.69589875289239,
    "num_requests": 128,
    "output_throughput": 3489.001970050663,
    "requests_per_second": 27.257827891020806,
    "resource_usage": {
      "avg_cpu_usage": 0.15000000000000002,
      "avg_gpu_memory_used": 35.968597412109375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 49,
    "timestamp": 1727308429,
    "tokens_per_second": 6978.003940101326,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.j1Ah231lkN",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 7.8866099489387125,
    "num_requests": 256,
    "output_throughput": 4154.890404388458,
    "requests_per_second": 32.460081284284826,
    "resource_usage": {
      "avg_cpu_usage": 1.3,
      "avg_gpu_memory_used": 36.391448974609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 54,
    "timestamp": 1727308483,
    "tokens_per_second": 8309.780808776915,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.byfm8hODLf",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 15.757588380947709,
    "num_requests": 512,
    "output_throughput": 4159.012052836632,
    "requests_per_second": 32.49228166278619,
    "resource_usage": {
      "avg_cpu_usage": 0.45,
      "avg_gpu_memory_used": 36.391448974609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 61,
    "timestamp": 1727308544,
    "tokens_per_second": 8318.024105673265,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.xzQk50gLBs",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 31.320278081810102,
    "num_requests": 1024,
    "output_throughput": 4184.892600813872,
    "requests_per_second": 32.69447344385838,
    "resource_usage": {
      "avg_cpu_usage": 0.39999999999999997,
      "avg_gpu_memory_used": 36.391448974609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 78,
    "timestamp": 1727308622,
    "tokens_per_second": 8369.785201627745,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]