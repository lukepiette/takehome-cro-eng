[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.eyjOtbUf2W",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.0959861734881997,
    "num_requests": 1,
    "output_throughput": 61.06910513964831,
    "requests_per_second": 0.4771023839035024,
    "resource_usage": {
      "avg_cpu_usage": 3.9,
      "avg_gpu_memory_used": 35.441253662109375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 82,
    "timestamp": 1727307864,
    "tokens_per_second": 122.13821027929662,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.JYfjEd2RYx",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.029600752517581,
    "num_requests": 2,
    "output_throughput": 126.1331814557368,
    "requests_per_second": 0.9854154801229438,
    "resource_usage": {
      "avg_cpu_usage": 3.1,
      "avg_gpu_memory_used": 35.450042724609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 40,
    "timestamp": 1727307904,
    "tokens_per_second": 252.2663629114736,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.i3xLGJKJ09",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.0495369844138622,
    "num_requests": 4,
    "output_throughput": 249.8125205320091,
    "requests_per_second": 1.9516603166563211,
    "resource_usage": {
      "avg_cpu_usage": 3.75,
      "avg_gpu_memory_used": 35.456878662109375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 39,
    "timestamp": 1727307943,
    "tokens_per_second": 499.6250410640182,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.9Iwra1C65V",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.139411716721952,
    "num_requests": 8,
    "output_throughput": 478.63624939335784,
    "requests_per_second": 3.739345698385608,
    "resource_usage": {
      "avg_cpu_usage": 3.2,
      "avg_gpu_memory_used": 35.471527099609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 42,
    "timestamp": 1727307985,
    "tokens_per_second": 957.2724987867157,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.fgk2941fcx",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.3640645407140255,
    "num_requests": 16,
    "output_throughput": 866.3046057877237,
    "requests_per_second": 6.768004732716592,
    "resource_usage": {
      "avg_cpu_usage": 3.35,
      "avg_gpu_memory_used": 35.508636474609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 44,
    "timestamp": 1727308029,
    "tokens_per_second": 1732.6092115754475,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.rJInFVxhDE",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.768927729688585,
    "num_requests": 32,
    "output_throughput": 1479.2729893534158,
    "requests_per_second": 11.556820229323561,
    "resource_usage": {
      "avg_cpu_usage": 3.2,
      "avg_gpu_memory_used": 35.570159912109375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 46,
    "timestamp": 1727308075,
    "tokens_per_second": 2958.5459787068316,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.DGJyrkfXvr",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.5832973569631577,
    "num_requests": 64,
    "output_throughput": 2286.1624877659374,
    "requests_per_second": 17.860644435671386,
    "resource_usage": {
      "avg_cpu_usage": 2.9,
      "avg_gpu_memory_used": 35.723480224609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 41,
    "timestamp": 1727308116,
    "tokens_per_second": 4572.324975531875,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.neLQIPw0eb",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.91541794501245,
    "num_requests": 128,
    "output_throughput": 3333.1855364658113,
    "requests_per_second": 26.04051200363915,
    "resource_usage": {
      "avg_cpu_usage": 3.9,
      "avg_gpu_memory_used": 35.968597412109375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 44,
    "timestamp": 1727308160,
    "tokens_per_second": 6666.371072931623,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.EWFPjzmZ53",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 8.38674177788198,
    "num_requests": 256,
    "output_throughput": 3907.1192207703048,
    "requests_per_second": 30.524368912268006,
    "resource_usage": {
      "avg_cpu_usage": 2.65,
      "avg_gpu_memory_used": 36.391448974609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 46,
    "timestamp": 1727308206,
    "tokens_per_second": 7814.2384415406095,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.n1NUyqg0hw",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 16.51416798774153,
    "num_requests": 512,
    "output_throughput": 3968.471196892716,
    "requests_per_second": 31.003681225724343,
    "resource_usage": {
      "avg_cpu_usage": 3.0,
      "avg_gpu_memory_used": 36.391448974609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 55,
    "timestamp": 1727308261,
    "tokens_per_second": 7936.942393785432,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.UZvY3dw91A",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 33.215017636306584,
    "num_requests": 1024,
    "output_throughput": 3946.1668042809697,
    "requests_per_second": 30.829428158445076,
    "resource_usage": {
      "avg_cpu_usage": 2.7,
      "avg_gpu_memory_used": 36.391448974609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 80.0
    },
    "run_duration": 73,
    "timestamp": 1727308334,
    "tokens_per_second": 7892.333608561939,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]