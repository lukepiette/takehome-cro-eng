[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.tMyK60N5kP",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.903714068233967,
    "num_requests": 1,
    "output_throughput": 32.78928675683129,
    "requests_per_second": 0.25616630278774444,
    "resource_usage": {
      "avg_cpu_usage": 9.95,
      "avg_gpu_memory_used": 21.276031494140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 142,
    "timestamp": 1727309033,
    "tokens_per_second": 65.57857351366258,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.BoSb7phBS3",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.9828633815050125,
    "num_requests": 2,
    "output_throughput": 64.2753656047486,
    "requests_per_second": 0.5021512937870984,
    "resource_usage": {
      "avg_cpu_usage": 10.2,
      "avg_gpu_memory_used": 21.284820556640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 41,
    "timestamp": 1727309074,
    "tokens_per_second": 128.5507312094972,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.XkWJpPrzjA",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.020987071096897,
    "num_requests": 4,
    "output_throughput": 127.33191899080889,
    "requests_per_second": 0.9947806171156944,
    "resource_usage": {
      "avg_cpu_usage": 15.9,
      "avg_gpu_memory_used": 21.291656494140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 40,
    "timestamp": 1727309114,
    "tokens_per_second": 254.66383798161777,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.rUOuWMYTgp",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.187351942062378,
    "num_requests": 8,
    "output_throughput": 244.5459598735457,
    "requests_per_second": 1.9105153115120759,
    "resource_usage": {
      "avg_cpu_usage": 15.55,
      "avg_gpu_memory_used": 21.306304931640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 43,
    "timestamp": 1727309157,
    "tokens_per_second": 489.0919197470914,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.Wn0nDjUqzI",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.470454253256321,
    "num_requests": 16,
    "output_throughput": 458.11899283125814,
    "requests_per_second": 3.579054631494204,
    "resource_usage": {
      "avg_cpu_usage": 12.649999999999999,
      "avg_gpu_memory_used": 21.343414306640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 41,
    "timestamp": 1727309198,
    "tokens_per_second": 916.2379856625163,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.kTvZlbFXlE",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.882172159850597,
    "num_requests": 32,
    "output_throughput": 838.970824028734,
    "requests_per_second": 6.554459562724484,
    "resource_usage": {
      "avg_cpu_usage": 8.399999999999999,
      "avg_gpu_memory_used": 21.404937744140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 41,
    "timestamp": 1727309239,
    "tokens_per_second": 1677.941648057468,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.jO48MWi1DG",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 6.072971120476723,
    "num_requests": 64,
    "output_throughput": 1348.9278703101977,
    "requests_per_second": 10.53849898679842,
    "resource_usage": {
      "avg_cpu_usage": 9.8,
      "avg_gpu_memory_used": 21.558258056640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 42,
    "timestamp": 1727309281,
    "tokens_per_second": 2697.8557406203954,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.bhrCjJO8J5",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 8.10268072038889,
    "num_requests": 128,
    "output_throughput": 2022.0468466408545,
    "requests_per_second": 15.797240989381676,
    "resource_usage": {
      "avg_cpu_usage": 15.149999999999999,
      "avg_gpu_memory_used": 21.803375244140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 45,
    "timestamp": 1727309326,
    "tokens_per_second": 4044.093693281709,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.160LyXE8ZK",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 13.900557920336723,
    "num_requests": 256,
    "output_throughput": 2357.315453652398,
    "requests_per_second": 18.41652698165936,
    "resource_usage": {
      "avg_cpu_usage": 25.299999999999997,
      "avg_gpu_memory_used": 22.226226806640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 51,
    "timestamp": 1727309377,
    "tokens_per_second": 4714.630907304796,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.yXldg82q6M",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 28.160153575241566,
    "num_requests": 512,
    "output_throughput": 2327.2600351732212,
    "requests_per_second": 18.18171902479079,
    "resource_usage": {
      "avg_cpu_usage": 19.35,
      "avg_gpu_memory_used": 22.226226806640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 68,
    "timestamp": 1727309445,
    "tokens_per_second": 4654.5200703464425,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.pIB584A9MB",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 56.56451562792063,
    "num_requests": 1024,
    "output_throughput": 2317.212452806755,
    "requests_per_second": 18.103222287552775,
    "resource_usage": {
      "avg_cpu_usage": 16.55,
      "avg_gpu_memory_used": 22.226226806640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 95,
    "timestamp": 1727309540,
    "tokens_per_second": 4634.42490561351,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]