[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.eKKFSUgZCx",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.728248830884695,
    "num_requests": 1,
    "output_throughput": 27.071333294455684,
    "requests_per_second": 0.21149479136293503,
    "resource_usage": {
      "avg_cpu_usage": 12.05,
      "avg_gpu_memory_used": 20.02783203125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 85,
    "timestamp": 1727309077,
    "tokens_per_second": 54.14266658891137,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.19Y7kgLHBV",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.998702634125948,
    "num_requests": 2,
    "output_throughput": 51.213288474552975,
    "requests_per_second": 0.4001038162074451,
    "resource_usage": {
      "avg_cpu_usage": 10.8,
      "avg_gpu_memory_used": 20.03662109375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 46,
    "timestamp": 1727309123,
    "tokens_per_second": 102.42657694910595,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.8rlsmPvAVw",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 5.054742116481066,
    "num_requests": 4,
    "output_throughput": 101.29102300404524,
    "requests_per_second": 0.7913361172191035,
    "resource_usage": {
      "avg_cpu_usage": 9.350000000000001,
      "avg_gpu_memory_used": 20.04345703125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 44,
    "timestamp": 1727309167,
    "tokens_per_second": 202.5820460080905,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.eB25Ag8mjM",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 5.231454864144325,
    "num_requests": 8,
    "output_throughput": 195.73904900114033,
    "requests_per_second": 1.5292113203214088,
    "resource_usage": {
      "avg_cpu_usage": 8.899999999999999,
      "avg_gpu_memory_used": 20.05810546875,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 45,
    "timestamp": 1727309212,
    "tokens_per_second": 391.47809800228066,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.6nKD2bcMd2",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 5.569540344178677,
    "num_requests": 16,
    "output_throughput": 367.71436661565514,
    "requests_per_second": 2.8727684891848058,
    "resource_usage": {
      "avg_cpu_usage": 12.05,
      "avg_gpu_memory_used": 20.09521484375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 46,
    "timestamp": 1727309258,
    "tokens_per_second": 735.4287332313103,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.271ZBneKHx",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 5.959452509880066,
    "num_requests": 32,
    "output_throughput": 687.3114590995259,
    "requests_per_second": 5.369620774215046,
    "resource_usage": {
      "avg_cpu_usage": 11.4,
      "avg_gpu_memory_used": 20.15673828125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 46,
    "timestamp": 1727309304,
    "tokens_per_second": 1374.6229181990518,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.J7CVq5cZhU",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 7.298006866127253,
    "num_requests": 64,
    "output_throughput": 1122.4982588084563,
    "requests_per_second": 8.769517646941065,
    "resource_usage": {
      "avg_cpu_usage": 11.3,
      "avg_gpu_memory_used": 20.31005859375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 47,
    "timestamp": 1727309351,
    "tokens_per_second": 2244.9965176169126,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.cq0Gx5I04K",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 9.56191885843873,
    "num_requests": 128,
    "output_throughput": 1713.4636094031005,
    "requests_per_second": 13.386434448461722,
    "resource_usage": {
      "avg_cpu_usage": 12.5,
      "avg_gpu_memory_used": 20.55517578125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 49,
    "timestamp": 1727309400,
    "tokens_per_second": 3426.927218806201,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.3gVZOAvD9t",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 15.046375207602978,
    "num_requests": 256,
    "output_throughput": 2177.8002706885995,
    "requests_per_second": 17.014064614754684,
    "resource_usage": {
      "avg_cpu_usage": 9.9,
      "avg_gpu_memory_used": 20.97802734375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 56,
    "timestamp": 1727309456,
    "tokens_per_second": 4355.600541377199,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.Ll8CeCo5t6",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 30.085554115474224,
    "num_requests": 512,
    "output_throughput": 2178.3211885830674,
    "requests_per_second": 17.018134285805214,
    "resource_usage": {
      "avg_cpu_usage": 10.399999999999999,
      "avg_gpu_memory_used": 20.97802734375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 71,
    "timestamp": 1727309527,
    "tokens_per_second": 4356.642377166135,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.289V0KySYF",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 60.0853386297822,
    "num_requests": 1024,
    "output_throughput": 2181.4306616062277,
    "requests_per_second": 17.042427043798654,
    "resource_usage": {
      "avg_cpu_usage": 9.2,
      "avg_gpu_memory_used": 20.97802734375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 100,
    "timestamp": 1727309627,
    "tokens_per_second": 4362.861323212455,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]