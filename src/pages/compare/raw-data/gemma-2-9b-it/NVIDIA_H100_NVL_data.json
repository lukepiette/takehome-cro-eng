[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.hN9Sx0n24u",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.317317286040634,
    "num_requests": 1,
    "output_throughput": 97.16717555929173,
    "requests_per_second": 0.7591185590569667,
    "resource_usage": {
      "avg_cpu_usage": 0.95,
      "avg_gpu_memory_used": 41.40386962890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 93.583984375
    },
    "run_duration": 281,
    "timestamp": 1727308165,
    "tokens_per_second": 194.33435111858347,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.j6Q4gLSEcM",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.3183425890747458,
    "num_requests": 2,
    "output_throughput": 194.18321316591073,
    "requests_per_second": 1.5170563528586776,
    "resource_usage": {
      "avg_cpu_usage": 0.8,
      "avg_gpu_memory_used": 41.40289306640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 93.583984375
    },
    "run_duration": 33,
    "timestamp": 1727308198,
    "tokens_per_second": 388.36642633182146,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.eUSXgP5MQv",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.3301967878360301,
    "num_requests": 4,
    "output_throughput": 384.9054551040706,
    "requests_per_second": 3.0070738680005515,
    "resource_usage": {
      "avg_cpu_usage": 0.35,
      "avg_gpu_memory_used": 41.41754150390625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 93.583984375
    },
    "run_duration": 35,
    "timestamp": 1727308233,
    "tokens_per_second": 769.8109102081412,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.GpSfBQhFWp",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.3798963960725814,
    "num_requests": 8,
    "output_throughput": 742.0846977457708,
    "requests_per_second": 5.797536701138834,
    "resource_usage": {
      "avg_cpu_usage": 2.7,
      "avg_gpu_memory_used": 41.43218994140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 93.583984375
    },
    "run_duration": 35,
    "timestamp": 1727308268,
    "tokens_per_second": 1484.1693954915415,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.3RiYwhugQP",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.46942207403481,
    "num_requests": 16,
    "output_throughput": 1393.7452255474172,
    "requests_per_second": 10.888634574589197,
    "resource_usage": {
      "avg_cpu_usage": 1.0,
      "avg_gpu_memory_used": 41.46148681640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 93.583984375
    },
    "run_duration": 33,
    "timestamp": 1727308301,
    "tokens_per_second": 2787.4904510948345,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.AGLe2MR6sK",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.656235070899129,
    "num_requests": 32,
    "output_throughput": 2473.0788956041024,
    "requests_per_second": 19.32092887190705,
    "resource_usage": {
      "avg_cpu_usage": 2.05,
      "avg_gpu_memory_used": 41.52496337890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 93.583984375
    },
    "run_duration": 35,
    "timestamp": 1727308336,
    "tokens_per_second": 4946.157791208205,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.sed6Qd1LiM",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.495956133119762,
    "num_requests": 64,
    "output_throughput": 3282.1089646958662,
    "requests_per_second": 25.641476286686455,
    "resource_usage": {
      "avg_cpu_usage": 1.75,
      "avg_gpu_memory_used": 41.68609619140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 93.583984375
    },
    "run_duration": 34,
    "timestamp": 1727308370,
    "tokens_per_second": 6564.2179293917325,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.z30KQfimvY",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.0179299721494317,
    "num_requests": 128,
    "output_throughput": 5428.886737332404,
    "requests_per_second": 42.413177635409404,
    "resource_usage": {
      "avg_cpu_usage": 1.45,
      "avg_gpu_memory_used": 41.93121337890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 93.583984375
    },
    "run_duration": 37,
    "timestamp": 1727308407,
    "tokens_per_second": 10857.773474664808,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.5Cch2V4gMe",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 5.567208206979558,
    "num_requests": 256,
    "output_throughput": 5885.8944702156205,
    "requests_per_second": 45.983550548559535,
    "resource_usage": {
      "avg_cpu_usage": 1.05,
      "avg_gpu_memory_used": 42.35406494140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 93.583984375
    },
    "run_duration": 38,
    "timestamp": 1727308445,
    "tokens_per_second": 11771.788940431241,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.ySD8FEhZoM",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 11.232580059906468,
    "num_requests": 512,
    "output_throughput": 5834.456522942932,
    "requests_per_second": 45.581691585491654,
    "resource_usage": {
      "avg_cpu_usage": 0.75,
      "avg_gpu_memory_used": 42.35406494140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 93.583984375
    },
    "run_duration": 43,
    "timestamp": 1727308488,
    "tokens_per_second": 11668.913045885864,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.Ho8pS8qonc",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 22.637800083030015,
    "num_requests": 1024,
    "output_throughput": 5789.961900858713,
    "requests_per_second": 45.2340773504587,
    "resource_usage": {
      "avg_cpu_usage": 1.55,
      "avg_gpu_memory_used": 42.35406494140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 93.583984375
    },
    "run_duration": 58,
    "timestamp": 1727308546,
    "tokens_per_second": 11579.923801717427,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]