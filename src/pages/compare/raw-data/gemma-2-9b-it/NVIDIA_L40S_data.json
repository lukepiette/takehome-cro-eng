[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.CabhUtOnXR",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.5724344558548182,
    "num_requests": 1,
    "output_throughput": 35.8299085908273,
    "requests_per_second": 0.2799211608658383,
    "resource_usage": {
      "avg_cpu_usage": 5.1,
      "avg_gpu_memory_used": 19.9759521484375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 83,
    "timestamp": 1727308984,
    "tokens_per_second": 71.6598171816546,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.Sd2gG6F4Ft",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.7277000779286027,
    "num_requests": 2,
    "output_throughput": 68.67505288736999,
    "requests_per_second": 0.536523850682578,
    "resource_usage": {
      "avg_cpu_usage": 4.5,
      "avg_gpu_memory_used": 19.9847412109375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 46,
    "timestamp": 1727309030,
    "tokens_per_second": 137.35010577473997,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.KQbiYzxa24",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.7168746090028435,
    "num_requests": 4,
    "output_throughput": 137.7501406046513,
    "requests_per_second": 1.0761729734738383,
    "resource_usage": {
      "avg_cpu_usage": 2.95,
      "avg_gpu_memory_used": 19.9915771484375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 43,
    "timestamp": 1727309073,
    "tokens_per_second": 275.5002812093026,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.yXi5IzIOkn",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.810554180992767,
    "num_requests": 8,
    "output_throughput": 268.72731664799903,
    "requests_per_second": 2.0994321613124924,
    "resource_usage": {
      "avg_cpu_usage": 2.1,
      "avg_gpu_memory_used": 20.0062255859375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 45,
    "timestamp": 1727309119,
    "tokens_per_second": 537.4546332959981,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.8JYuYOfD1D",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.995496581075713,
    "num_requests": 16,
    "output_throughput": 512.5770873388194,
    "requests_per_second": 4.004508494834527,
    "resource_usage": {
      "avg_cpu_usage": 1.0,
      "avg_gpu_memory_used": 20.0433349609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 44,
    "timestamp": 1727309163,
    "tokens_per_second": 1025.1541746776388,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.efOOjK1d7K",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.382340082898736,
    "num_requests": 32,
    "output_throughput": 934.6604605114686,
    "requests_per_second": 7.3020348477458485,
    "resource_usage": {
      "avg_cpu_usage": 4.6000000000000005,
      "avg_gpu_memory_used": 20.1048583984375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 44,
    "timestamp": 1727309207,
    "tokens_per_second": 1869.3209210229372,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.QE77jhVzQF",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 5.531210127053782,
    "num_requests": 64,
    "output_throughput": 1481.0502244223176,
    "requests_per_second": 11.570704878299356,
    "resource_usage": {
      "avg_cpu_usage": 2.25,
      "avg_gpu_memory_used": 20.2581787109375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 45,
    "timestamp": 1727309252,
    "tokens_per_second": 2962.100448844635,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.AeGljRik9f",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 7.278096873080358,
    "num_requests": 128,
    "output_throughput": 2251.13793972705,
    "requests_per_second": 17.587015154117577,
    "resource_usage": {
      "avg_cpu_usage": 2.25,
      "avg_gpu_memory_used": 20.5032958984375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 48,
    "timestamp": 1727309300,
    "tokens_per_second": 4502.2758794541,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.V5RBEjhD48",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 11.117668312042952,
    "num_requests": 256,
    "output_throughput": 2947.380608981187,
    "requests_per_second": 23.026411007665523,
    "resource_usage": {
      "avg_cpu_usage": 1.4,
      "avg_gpu_memory_used": 20.9261474609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 52,
    "timestamp": 1727309352,
    "tokens_per_second": 5894.761217962374,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.KAjrDBJI3e",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 22.068214731058106,
    "num_requests": 512,
    "output_throughput": 2969.7010292258356,
    "requests_per_second": 23.20078929082684,
    "resource_usage": {
      "avg_cpu_usage": 1.2,
      "avg_gpu_memory_used": 20.9261474609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 62,
    "timestamp": 1727309414,
    "tokens_per_second": 5939.402058451671,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.8PKPTcUOyl",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 44.1150346188806,
    "num_requests": 1024,
    "output_throughput": 2971.141270370965,
    "requests_per_second": 23.212041174773162,
    "resource_usage": {
      "avg_cpu_usage": 0.9,
      "avg_gpu_memory_used": 20.9261474609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 85,
    "timestamp": 1727309499,
    "tokens_per_second": 5942.28254074193,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]