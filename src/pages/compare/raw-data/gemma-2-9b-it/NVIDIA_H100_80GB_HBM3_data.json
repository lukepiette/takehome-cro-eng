[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.l3EkXopkRs",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.3071421831846237,
    "num_requests": 1,
    "output_throughput": 97.9235477567944,
    "requests_per_second": 0.7650277168499563,
    "resource_usage": {
      "avg_cpu_usage": 3.4000000000000004,
      "avg_gpu_memory_used": 35.13958740234375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 273,
    "timestamp": 1727308054,
    "tokens_per_second": 195.8470955135888,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.GyLwl7bZxE",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.328464746940881,
    "num_requests": 2,
    "output_throughput": 192.70364576064466,
    "requests_per_second": 1.5054972325050364,
    "resource_usage": {
      "avg_cpu_usage": 2.7,
      "avg_gpu_memory_used": 35.13861083984375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 34,
    "timestamp": 1727308088,
    "tokens_per_second": 385.4072915212893,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.2QJQOVg4KY",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.2976501411758363,
    "num_requests": 4,
    "output_throughput": 394.55935290544704,
    "requests_per_second": 3.082494944573805,
    "resource_usage": {
      "avg_cpu_usage": 3.0999999999999996,
      "avg_gpu_memory_used": 35.15325927734375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 34,
    "timestamp": 1727308122,
    "tokens_per_second": 789.1187058108941,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.MwmUpaU51a",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.323721116175875,
    "num_requests": 8,
    "output_throughput": 773.5768414409332,
    "requests_per_second": 6.043569073757291,
    "resource_usage": {
      "avg_cpu_usage": 3.2,
      "avg_gpu_memory_used": 35.16790771484375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 37,
    "timestamp": 1727308159,
    "tokens_per_second": 1547.1536828818664,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.muda4KlaxL",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.3684626349713653,
    "num_requests": 16,
    "output_throughput": 1496.569908204219,
    "requests_per_second": 11.691952407845461,
    "resource_usage": {
      "avg_cpu_usage": 2.7,
      "avg_gpu_memory_used": 35.19720458984375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 35,
    "timestamp": 1727308194,
    "tokens_per_second": 2993.139816408438,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.GPI3OrRWO8",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.4957734229974449,
    "num_requests": 32,
    "output_throughput": 2738.3826567742117,
    "requests_per_second": 21.39361450604853,
    "resource_usage": {
      "avg_cpu_usage": 3.2,
      "avg_gpu_memory_used": 35.26068115234375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 34,
    "timestamp": 1727308228,
    "tokens_per_second": 5476.765313548423,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.LCg5CzHrpT",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.7956566759385169,
    "num_requests": 64,
    "output_throughput": 4562.119312545297,
    "requests_per_second": 35.641557129260136,
    "resource_usage": {
      "avg_cpu_usage": 2.8499999999999996,
      "avg_gpu_memory_used": 35.42181396484375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 34,
    "timestamp": 1727308262,
    "tokens_per_second": 9124.238625090595,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.MGyTR24Has",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.3631385748740286,
    "num_requests": 128,
    "output_throughput": 6933.152449967256,
    "requests_per_second": 54.16525351536919,
    "resource_usage": {
      "avg_cpu_usage": 2.7,
      "avg_gpu_memory_used": 35.66693115234375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 34,
    "timestamp": 1727308296,
    "tokens_per_second": 13866.304899934512,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.kJf9BUoIs7",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.896197770955041,
    "num_requests": 256,
    "output_throughput": 8410.2506921685,
    "requests_per_second": 65.7050835325664,
    "resource_usage": {
      "avg_cpu_usage": 5.0,
      "avg_gpu_memory_used": 36.08978271484375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 36,
    "timestamp": 1727308332,
    "tokens_per_second": 16820.501384337,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.NkfxIAkxdk",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 7.787763759959489,
    "num_requests": 512,
    "output_throughput": 8415.252698977723,
    "requests_per_second": 65.74416171076346,
    "resource_usage": {
      "avg_cpu_usage": 3.3,
      "avg_gpu_memory_used": 36.08978271484375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 38,
    "timestamp": 1727308370,
    "tokens_per_second": 16830.505397955447,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.SuuEUSewAO",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 15.639942146837711,
    "num_requests": 1024,
    "output_throughput": 8380.593660092398,
    "requests_per_second": 65.47338796947186,
    "resource_usage": {
      "avg_cpu_usage": 2.9000000000000004,
      "avg_gpu_memory_used": 36.08978271484375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 48,
    "timestamp": 1727308418,
    "tokens_per_second": 16761.187320184796,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]