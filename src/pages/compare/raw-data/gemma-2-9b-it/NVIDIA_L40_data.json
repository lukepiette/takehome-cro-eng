[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.vVRv3w97Os",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.5946225747466087,
    "num_requests": 1,
    "output_throughput": 35.60874537962388,
    "requests_per_second": 0.2781933232783116,
    "resource_usage": {
      "avg_cpu_usage": 2.3499999999999996,
      "avg_gpu_memory_used": 20.0982666015625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 220,
    "timestamp": 1727309173,
    "tokens_per_second": 71.21749075924777,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.cZY6otg5O2",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.7603878155350685,
    "num_requests": 2,
    "output_throughput": 68.07808464393015,
    "requests_per_second": 0.5318600362807043,
    "resource_usage": {
      "avg_cpu_usage": 1.6,
      "avg_gpu_memory_used": 20.1070556640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 44,
    "timestamp": 1727309217,
    "tokens_per_second": 136.1561692878603,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.WfhDSVZERr",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.761014774441719,
    "num_requests": 4,
    "output_throughput": 136.1334721361207,
    "requests_per_second": 1.063542751063443,
    "resource_usage": {
      "avg_cpu_usage": 1.6,
      "avg_gpu_memory_used": 20.1138916015625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 44,
    "timestamp": 1727309261,
    "tokens_per_second": 272.2669442722414,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.Qs0ipvEX0E",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.8423076421022415,
    "num_requests": 8,
    "output_throughput": 266.50650998880946,
    "requests_per_second": 2.082082109287574,
    "resource_usage": {
      "avg_cpu_usage": 1.7000000000000002,
      "avg_gpu_memory_used": 20.1285400390625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 44,
    "timestamp": 1727309305,
    "tokens_per_second": 533.0130199776189,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.QKmBKH9qpk",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.051838621497154,
    "num_requests": 16,
    "output_throughput": 505.4495480482054,
    "requests_per_second": 3.9488245941266045,
    "resource_usage": {
      "avg_cpu_usage": 2.15,
      "avg_gpu_memory_used": 20.1656494140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 43,
    "timestamp": 1727309349,
    "tokens_per_second": 1010.8990960964107,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.kyTUT9Df20",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.522182330489159,
    "num_requests": 32,
    "output_throughput": 905.7573756777164,
    "requests_per_second": 7.076229497482159,
    "resource_usage": {
      "avg_cpu_usage": 2.7,
      "avg_gpu_memory_used": 20.2271728515625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 43,
    "timestamp": 1727309392,
    "tokens_per_second": 1811.5147513554327,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.VP50hkJ5bJ",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 5.778556372970343,
    "num_requests": 64,
    "output_throughput": 1417.6551150939242,
    "requests_per_second": 11.075430586671283,
    "resource_usage": {
      "avg_cpu_usage": 1.9,
      "avg_gpu_memory_used": 20.3804931640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 47,
    "timestamp": 1727309439,
    "tokens_per_second": 2835.3102301878484,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.tpGoqFysly",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 7.693897221237421,
    "num_requests": 128,
    "output_throughput": 2129.4799668983537,
    "requests_per_second": 16.63656224139339,
    "resource_usage": {
      "avg_cpu_usage": 2.3,
      "avg_gpu_memory_used": 20.6256103515625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 49,
    "timestamp": 1727309488,
    "tokens_per_second": 4258.959933796707,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.CDvHMwbACj",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 12.136620569974184,
    "num_requests": 256,
    "output_throughput": 2699.9278597427306,
    "requests_per_second": 21.093186404240083,
    "resource_usage": {
      "avg_cpu_usage": 2.55,
      "avg_gpu_memory_used": 21.0484619140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 52,
    "timestamp": 1727309540,
    "tokens_per_second": 5399.855719485461,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.PoF6yG6A3T",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 24.27026291564107,
    "num_requests": 512,
    "output_throughput": 2700.2591701536558,
    "requests_per_second": 21.095774766825436,
    "resource_usage": {
      "avg_cpu_usage": 1.8,
      "avg_gpu_memory_used": 21.0484619140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 64,
    "timestamp": 1727309604,
    "tokens_per_second": 5400.5183403073115,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.kDShzfvgGJ",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 48.41194737702608,
    "num_requests": 1024,
    "output_throughput": 2707.430853364108,
    "requests_per_second": 21.151803541907093,
    "resource_usage": {
      "avg_cpu_usage": 1.95,
      "avg_gpu_memory_used": 21.0484619140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 88,
    "timestamp": 1727309692,
    "tokens_per_second": 5414.861706728216,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]