[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.CDw8Unxw8b",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.7906343508511782,
    "num_requests": 1,
    "output_throughput": 71.48304730061454,
    "requests_per_second": 0.5584613070360511,
    "resource_usage": {
      "avg_cpu_usage": 0.95,
      "avg_gpu_memory_used": 35.17633056640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 218,
    "timestamp": 1727308193,
    "tokens_per_second": 142.9660946012291,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.nYnaJEq2YO",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.7897478193044662,
    "num_requests": 2,
    "output_throughput": 143.03691125573602,
    "requests_per_second": 1.1174758691854376,
    "resource_usage": {
      "avg_cpu_usage": 0.9,
      "avg_gpu_memory_used": 35.17535400390625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 36,
    "timestamp": 1727308229,
    "tokens_per_second": 286.07382251147203,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.l1h4r8WRRB",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.829971693456173,
    "num_requests": 4,
    "output_throughput": 279.7857485068592,
    "requests_per_second": 2.1858261602098374,
    "resource_usage": {
      "avg_cpu_usage": 1.25,
      "avg_gpu_memory_used": 35.19000244140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 38,
    "timestamp": 1727308267,
    "tokens_per_second": 559.5714970137184,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.w92i3eXG07",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.9145588260143995,
    "num_requests": 8,
    "output_throughput": 534.8490660543947,
    "requests_per_second": 4.178508328549959,
    "resource_usage": {
      "avg_cpu_usage": 0.8,
      "avg_gpu_memory_used": 35.20465087890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 38,
    "timestamp": 1727308305,
    "tokens_per_second": 1069.6981321087894,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.3f7ogMvotz",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.957263832911849,
    "num_requests": 16,
    "output_throughput": 1046.3586796845684,
    "requests_per_second": 8.17467718503569,
    "resource_usage": {
      "avg_cpu_usage": 0.75,
      "avg_gpu_memory_used": 35.23394775390625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 36,
    "timestamp": 1727308341,
    "tokens_per_second": 2092.717359369137,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.gWM5VIi0vi",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.236584195867181,
    "num_requests": 32,
    "output_throughput": 1831.3640986861558,
    "requests_per_second": 14.307532020985592,
    "resource_usage": {
      "avg_cpu_usage": 0.8,
      "avg_gpu_memory_used": 35.29742431640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 37,
    "timestamp": 1727308378,
    "tokens_per_second": 3662.7281973723116,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.K7vBh84Bco",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.598767187446356,
    "num_requests": 64,
    "output_throughput": 3152.263904043579,
    "requests_per_second": 24.62706175034046,
    "resource_usage": {
      "avg_cpu_usage": 0.8,
      "avg_gpu_memory_used": 35.45855712890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 37,
    "timestamp": 1727308415,
    "tokens_per_second": 6304.527808087158,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.PO6DJpVnnm",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.5052668917924166,
    "num_requests": 128,
    "output_throughput": 4674.109135131233,
    "requests_per_second": 36.51647761821276,
    "resource_usage": {
      "avg_cpu_usage": 1.5,
      "avg_gpu_memory_used": 35.70367431640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 37,
    "timestamp": 1727308452,
    "tokens_per_second": 9348.218270262467,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.YiLPK6YgoA",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 5.597780918702483,
    "num_requests": 256,
    "output_throughput": 5853.748204135744,
    "requests_per_second": 45.7324078448105,
    "resource_usage": {
      "avg_cpu_usage": 1.0,
      "avg_gpu_memory_used": 36.12652587890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 40,
    "timestamp": 1727308492,
    "tokens_per_second": 11707.496408271489,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.llJEiZziyQ",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 11.60727534070611,
    "num_requests": 512,
    "output_throughput": 5646.114016970775,
    "requests_per_second": 44.11026575758418,
    "resource_usage": {
      "avg_cpu_usage": 0.9500000000000001,
      "avg_gpu_memory_used": 36.12652587890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 46,
    "timestamp": 1727308538,
    "tokens_per_second": 11292.22803394155,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.EySHqdOkEL",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 22.439228247851133,
    "num_requests": 1024,
    "output_throughput": 5841.199106861082,
    "requests_per_second": 45.634368022352206,
    "resource_usage": {
      "avg_cpu_usage": 0.8500000000000001,
      "avg_gpu_memory_used": 36.12652587890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 56,
    "timestamp": 1727308594,
    "tokens_per_second": 11682.398213722165,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]