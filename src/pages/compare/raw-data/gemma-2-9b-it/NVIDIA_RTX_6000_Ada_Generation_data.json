[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.voAQF629Zc",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.0049657244235277,
    "num_requests": 1,
    "output_throughput": 42.59615973641613,
    "requests_per_second": 0.33278249794075104,
    "resource_usage": {
      "avg_cpu_usage": 1.4,
      "avg_gpu_memory_used": 21.3489990234375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 63,
    "timestamp": 1727309066,
    "tokens_per_second": 85.19231947283227,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.AXgAhFAxYR",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.07110283896327,
    "num_requests": 2,
    "output_throughput": 83.35767749360663,
    "requests_per_second": 0.6512318554188018,
    "resource_usage": {
      "avg_cpu_usage": 1.4500000000000002,
      "avg_gpu_memory_used": 21.3577880859375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 40,
    "timestamp": 1727309106,
    "tokens_per_second": 166.71535498721326,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.xnlpX3BG6a",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.080981897190213,
    "num_requests": 4,
    "output_throughput": 166.18078816591964,
    "requests_per_second": 1.2982874075462472,
    "resource_usage": {
      "avg_cpu_usage": 1.1,
      "avg_gpu_memory_used": 21.3646240234375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 38,
    "timestamp": 1727309144,
    "tokens_per_second": 332.3615763318393,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.mEPs6NZvTL",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.3247423004359007,
    "num_requests": 8,
    "output_throughput": 307.9937954486714,
    "requests_per_second": 2.4062015269427453,
    "resource_usage": {
      "avg_cpu_usage": 1.25,
      "avg_gpu_memory_used": 21.3792724609375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 38,
    "timestamp": 1727309182,
    "tokens_per_second": 615.9875908973428,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.sEUuIZPwLb",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.3453090395778418,
    "num_requests": 16,
    "output_throughput": 612.2005398516023,
    "requests_per_second": 4.782816717590643,
    "resource_usage": {
      "avg_cpu_usage": 1.55,
      "avg_gpu_memory_used": 21.4163818359375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 39,
    "timestamp": 1727309221,
    "tokens_per_second": 1224.4010797032047,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.CLSI2esX9z",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.6898795384913683,
    "num_requests": 32,
    "output_throughput": 1110.0633387274959,
    "requests_per_second": 8.672369833808562,
    "resource_usage": {
      "avg_cpu_usage": 1.0,
      "avg_gpu_memory_used": 21.4779052734375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 39,
    "timestamp": 1727309260,
    "tokens_per_second": 2220.1266774549917,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.IvD8RYOljl",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 5.28569726832211,
    "num_requests": 64,
    "output_throughput": 1549.8428275670933,
    "requests_per_second": 12.108147090367916,
    "resource_usage": {
      "avg_cpu_usage": 2.45,
      "avg_gpu_memory_used": 21.6312255859375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 45,
    "timestamp": 1727309305,
    "tokens_per_second": 3099.6856551341866,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.80N3HxZCqj",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 6.2883420009166,
    "num_requests": 128,
    "output_throughput": 2605.4562550210912,
    "requests_per_second": 20.355126992352275,
    "resource_usage": {
      "avg_cpu_usage": 1.95,
      "avg_gpu_memory_used": 21.8763427734375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 41,
    "timestamp": 1727309346,
    "tokens_per_second": 5210.9125100421825,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.p1y9VNaa38",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 9.882395131513476,
    "num_requests": 256,
    "output_throughput": 3315.795367816023,
    "requests_per_second": 25.90465131106268,
    "resource_usage": {
      "avg_cpu_usage": 7.0,
      "avg_gpu_memory_used": 22.2991943359375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 44,
    "timestamp": 1727309390,
    "tokens_per_second": 6631.590735632046,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.s8X3QohlfJ",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 19.94940941594541,
    "num_requests": 512,
    "output_throughput": 3285.109781125529,
    "requests_per_second": 25.664920165043196,
    "resource_usage": {
      "avg_cpu_usage": 2.7,
      "avg_gpu_memory_used": 22.2991943359375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 54,
    "timestamp": 1727309444,
    "tokens_per_second": 6570.219562251058,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "google/gemma-2-9b-it",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.BBXUWUq82t",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "google/gemma-2-9b-it",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 39.959200570359826,
    "num_requests": 1024,
    "output_throughput": 3280.145701844298,
    "requests_per_second": 25.626138295658578,
    "resource_usage": {
      "avg_cpu_usage": 2.75,
      "avg_gpu_memory_used": 22.2991943359375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 47.98828125
    },
    "run_duration": 74,
    "timestamp": 1727309518,
    "tokens_per_second": 6560.291403688596,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]