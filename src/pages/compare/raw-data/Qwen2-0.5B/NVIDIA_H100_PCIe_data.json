[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.oMATl8ve41",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.36461006943136454,
    "num_requests": 1,
    "output_throughput": 351.0599699005163,
    "requests_per_second": 2.7426560148477837,
    "resource_usage": {
      "avg_cpu_usage": 1.35,
      "avg_gpu_memory_used": 34.14312744140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 47,
    "timestamp": 1727306569,
    "tokens_per_second": 702.1199398010326,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.YKzWtFbbEk",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.41126210149377584,
    "num_requests": 2,
    "output_throughput": 622.4740842157914,
    "requests_per_second": 4.863078782935871,
    "resource_usage": {
      "avg_cpu_usage": 0.9,
      "avg_gpu_memory_used": 34.14215087890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 30,
    "timestamp": 1727306599,
    "tokens_per_second": 1244.9481684315829,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.e79954nEsV",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.40181690361350775,
    "num_requests": 4,
    "output_throughput": 1274.2121981320954,
    "requests_per_second": 9.954782797906995,
    "resource_usage": {
      "avg_cpu_usage": 0.95,
      "avg_gpu_memory_used": 34.14312744140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 32,
    "timestamp": 1727306631,
    "tokens_per_second": 2548.424396264191,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.i4sQB85KHx",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.426864393055439,
    "num_requests": 8,
    "output_throughput": 2398.8883042465623,
    "requests_per_second": 18.741314876926268,
    "resource_usage": {
      "avg_cpu_usage": 1.05,
      "avg_gpu_memory_used": 34.15093994140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 35,
    "timestamp": 1727306666,
    "tokens_per_second": 4797.7766084931245,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.l8w5HtVjyJ",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.4718417255207896,
    "num_requests": 16,
    "output_throughput": 4340.438518317863,
    "requests_per_second": 33.909675924358304,
    "resource_usage": {
      "avg_cpu_usage": 1.6,
      "avg_gpu_memory_used": 34.16949462890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 30,
    "timestamp": 1727306696,
    "tokens_per_second": 8680.877036635726,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.TRxY9euvst",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.5575075764209032,
    "num_requests": 32,
    "output_throughput": 7346.985356316719,
    "requests_per_second": 57.39832309622437,
    "resource_usage": {
      "avg_cpu_usage": 1.3,
      "avg_gpu_memory_used": 34.21636962890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 29,
    "timestamp": 1727306725,
    "tokens_per_second": 14693.970712633438,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.LSqmgoZFvt",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.7590704644098878,
    "num_requests": 64,
    "output_throughput": 10792.146953535568,
    "requests_per_second": 84.31364807449663,
    "resource_usage": {
      "avg_cpu_usage": 1.5,
      "avg_gpu_memory_used": 34.27886962890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 29,
    "timestamp": 1727306754,
    "tokens_per_second": 21584.293907071136,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.WMGjZ9xoWR",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.222350049763918,
    "num_requests": 128,
    "output_throughput": 13403.689068580945,
    "requests_per_second": 104.71632084828863,
    "resource_usage": {
      "avg_cpu_usage": 0.95,
      "avg_gpu_memory_used": 34.42633056640625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 32,
    "timestamp": 1727306786,
    "tokens_per_second": 26807.37813716189,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.JZaWrHwnR8",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.4977141423150897,
    "num_requests": 256,
    "output_throughput": 13119.195445491567,
    "requests_per_second": 102.49371441790286,
    "resource_usage": {
      "avg_cpu_usage": 1.8499999999999999,
      "avg_gpu_memory_used": 34.72906494140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 31,
    "timestamp": 1727306817,
    "tokens_per_second": 26238.390890983133,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.lMvr0Y3LPA",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 4.7646621856838465,
    "num_requests": 512,
    "output_throughput": 13754.595277900897,
    "requests_per_second": 107.45777560860076,
    "resource_usage": {
      "avg_cpu_usage": 0.9,
      "avg_gpu_memory_used": 34.72906494140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 34,
    "timestamp": 1727306851,
    "tokens_per_second": 27509.190555801793,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.35pYfUq7c5",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 9.638979232870042,
    "num_requests": 1024,
    "output_throughput": 13598.120385302751,
    "requests_per_second": 106.23531551017774,
    "resource_usage": {
      "avg_cpu_usage": 1.2,
      "avg_gpu_memory_used": 34.72906494140625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 40,
    "timestamp": 1727306891,
    "tokens_per_second": 27196.240770605502,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]