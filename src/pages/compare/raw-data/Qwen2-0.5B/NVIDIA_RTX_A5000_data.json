[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.LEWOty4frd",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.43078132532536983,
    "num_requests": 1,
    "output_throughput": 297.13451460162855,
    "requests_per_second": 2.321363395325223,
    "resource_usage": {
      "avg_cpu_usage": 2.1,
      "avg_gpu_memory_used": 8.812530517578125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 23.98828125
    },
    "run_duration": 35,
    "timestamp": 1727305211,
    "tokens_per_second": 594.2690292032571,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.n85fcTaQv5",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.4771659607067704,
    "num_requests": 2,
    "output_throughput": 536.5009683859615,
    "requests_per_second": 4.191413815515324,
    "resource_usage": {
      "avg_cpu_usage": 2.1,
      "avg_gpu_memory_used": 8.811553955078125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 23.98828125
    },
    "run_duration": 21,
    "timestamp": 1727305232,
    "tokens_per_second": 1073.001936771923,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.RqTJY62JpA",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.47725466545671225,
    "num_requests": 4,
    "output_throughput": 1072.8025036906406,
    "requests_per_second": 8.38126956008313,
    "resource_usage": {
      "avg_cpu_usage": 1.9,
      "avg_gpu_memory_used": 8.822296142578125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 23.98828125
    },
    "run_duration": 20,
    "timestamp": 1727305252,
    "tokens_per_second": 2145.605007381281,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.kw532fp0nx",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.5012871138751507,
    "num_requests": 8,
    "output_throughput": 2042.7415180974208,
    "requests_per_second": 15.9589181101361,
    "resource_usage": {
      "avg_cpu_usage": 2.5,
      "avg_gpu_memory_used": 8.830108642578125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 23.98828125
    },
    "run_duration": 21,
    "timestamp": 1727305273,
    "tokens_per_second": 4085.4830361948416,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.u0rDKp8tgA",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.5612213164567947,
    "num_requests": 16,
    "output_throughput": 3649.184269994962,
    "requests_per_second": 28.50925210933564,
    "resource_usage": {
      "avg_cpu_usage": 2.2,
      "avg_gpu_memory_used": 8.848663330078125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 23.98828125
    },
    "run_duration": 21,
    "timestamp": 1727305294,
    "tokens_per_second": 7298.368539989924,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.q1mkbPNchU",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.8505087979137897,
    "num_requests": 32,
    "output_throughput": 4815.940775741609,
    "requests_per_second": 37.62453731048132,
    "resource_usage": {
      "avg_cpu_usage": 0.35,
      "avg_gpu_memory_used": 8.885772705078125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 23.98828125
    },
    "run_duration": 21,
    "timestamp": 1727305315,
    "tokens_per_second": 9631.881551483219,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.toKEjgFHfS",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.1076402068138123,
    "num_requests": 64,
    "output_throughput": 7395.903425684353,
    "requests_per_second": 57.78049551315901,
    "resource_usage": {
      "avg_cpu_usage": 0.25,
      "avg_gpu_memory_used": 8.958038330078125,
      "avg_gpu_usage": 0.5,
      "total_gpu_memory": 23.98828125
    },
    "run_duration": 22,
    "timestamp": 1727305337,
    "tokens_per_second": 14791.806851368707,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.Ksk6Oy4bIr",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.7675553346052766,
    "num_requests": 128,
    "output_throughput": 9269.299624873589,
    "requests_per_second": 72.41640331932491,
    "resource_usage": {
      "avg_cpu_usage": 0.65,
      "avg_gpu_memory_used": 9.105499267578125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 23.98828125
    },
    "run_duration": 22,
    "timestamp": 1727305359,
    "tokens_per_second": 18538.599249747178,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.NubmqVEI3C",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 2.9956813687458634,
    "num_requests": 256,
    "output_throughput": 10938.412990737485,
    "requests_per_second": 85.4563514901366,
    "resource_usage": {
      "avg_cpu_usage": 0.45,
      "avg_gpu_memory_used": 9.398468017578125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 23.98828125
    },
    "run_duration": 24,
    "timestamp": 1727305383,
    "tokens_per_second": 21876.82598147497,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.xXLtuDWl5F",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 5.9797552395612,
    "num_requests": 512,
    "output_throughput": 10959.645900959835,
    "requests_per_second": 85.62223360124871,
    "resource_usage": {
      "avg_cpu_usage": 0.1,
      "avg_gpu_memory_used": 9.398468017578125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 23.98828125
    },
    "run_duration": 27,
    "timestamp": 1727305410,
    "tokens_per_second": 21919.29180191967,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.Oaaq2hTX5o",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 11.645880846306682,
    "num_requests": 1024,
    "output_throughput": 11254.794869515392,
    "requests_per_second": 87.928084918089,
    "resource_usage": {
      "avg_cpu_usage": 0.30000000000000004,
      "avg_gpu_memory_used": 9.398468017578125,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 23.98828125
    },
    "run_duration": 33,
    "timestamp": 1727305443,
    "tokens_per_second": 22509.589739030784,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]