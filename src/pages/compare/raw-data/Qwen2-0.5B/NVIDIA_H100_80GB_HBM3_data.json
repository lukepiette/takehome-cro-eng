[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.LY600imuuz",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.2885257564485073,
    "num_requests": 1,
    "output_throughput": 443.6345703605977,
    "requests_per_second": 3.4658950809421696,
    "resource_usage": {
      "avg_cpu_usage": 2.0,
      "avg_gpu_memory_used": 34.11224365234375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 38,
    "timestamp": 1727307138,
    "tokens_per_second": 887.2691407211954,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.XFFULG97Qa",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.3320977669209242,
    "num_requests": 2,
    "output_throughput": 770.8573363004762,
    "requests_per_second": 6.02232293984747,
    "resource_usage": {
      "avg_cpu_usage": 1.05,
      "avg_gpu_memory_used": 34.11126708984375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 18,
    "timestamp": 1727307156,
    "tokens_per_second": 1541.7146726009523,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.mQ02O5jsmn",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.33302731439471245,
    "num_requests": 4,
    "output_throughput": 1537.4114310430543,
    "requests_per_second": 12.011026805023862,
    "resource_usage": {
      "avg_cpu_usage": 0.75,
      "avg_gpu_memory_used": 34.11224365234375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 18,
    "timestamp": 1727307174,
    "tokens_per_second": 3074.8228620861087,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.BWKHBRBZdQ",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.34425341337919235,
    "num_requests": 8,
    "output_throughput": 2974.552931656983,
    "requests_per_second": 23.23869477857018,
    "resource_usage": {
      "avg_cpu_usage": 0.8500000000000001,
      "avg_gpu_memory_used": 34.12005615234375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 17,
    "timestamp": 1727307191,
    "tokens_per_second": 5949.105863313966,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.gfCqasygle",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.37019302882254124,
    "num_requests": 16,
    "output_throughput": 5532.248963504243,
    "requests_per_second": 43.2206950273769,
    "resource_usage": {
      "avg_cpu_usage": 0.75,
      "avg_gpu_memory_used": 34.13861083984375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 19,
    "timestamp": 1727307210,
    "tokens_per_second": 11064.497927008486,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.Nyr1c1ps89",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.42614571936428547,
    "num_requests": 32,
    "output_throughput": 9611.73564317464,
    "requests_per_second": 75.09168471230187,
    "resource_usage": {
      "avg_cpu_usage": 0.7,
      "avg_gpu_memory_used": 34.18548583984375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 18,
    "timestamp": 1727307228,
    "tokens_per_second": 19223.47128634928,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.KQnKzBvxjN",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.5635755751281977,
    "num_requests": 64,
    "output_throughput": 14535.76123865295,
    "requests_per_second": 113.56063467697618,
    "resource_usage": {
      "avg_cpu_usage": 0.6499999999999999,
      "avg_gpu_memory_used": 34.24798583984375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 18,
    "timestamp": 1727307246,
    "tokens_per_second": 29071.5224773059,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.mDaKQLq4ka",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.8457248285412788,
    "num_requests": 128,
    "output_throughput": 19372.73146900442,
    "requests_per_second": 151.34946460159702,
    "resource_usage": {
      "avg_cpu_usage": 0.75,
      "avg_gpu_memory_used": 34.39544677734375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 19,
    "timestamp": 1727307265,
    "tokens_per_second": 38745.46293800884,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.VT2P1qZRXm",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.7555002830922604,
    "num_requests": 256,
    "output_throughput": 18665.904138893195,
    "requests_per_second": 145.82737608510308,
    "resource_usage": {
      "avg_cpu_usage": 0.8999999999999999,
      "avg_gpu_memory_used": 34.69818115234375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 19,
    "timestamp": 1727307284,
    "tokens_per_second": 37331.80827778639,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.3YGXoXFMvw",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.220972064882517,
    "num_requests": 512,
    "output_throughput": 20346.65271224275,
    "requests_per_second": 158.9582243143965,
    "resource_usage": {
      "avg_cpu_usage": 1.9,
      "avg_gpu_memory_used": 34.69818115234375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 21,
    "timestamp": 1727307305,
    "tokens_per_second": 40693.3054244855,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.nwNWtkxqMd",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 6.4888614024966955,
    "num_requests": 1024,
    "output_throughput": 20199.537618351333,
    "requests_per_second": 157.8088876433698,
    "resource_usage": {
      "avg_cpu_usage": 1.25,
      "avg_gpu_memory_used": 34.69818115234375,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 79.6474609375
    },
    "run_duration": 26,
    "timestamp": 1727307331,
    "tokens_per_second": 40399.075236702665,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]