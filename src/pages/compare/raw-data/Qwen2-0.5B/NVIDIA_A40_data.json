[
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 1,
      "output_json": "/tmp/tmp.NFTrCMPXtI",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.47667644917964935,
    "num_requests": 1,
    "output_throughput": 268.5259576391606,
    "requests_per_second": 2.097859044055942,
    "resource_usage": {
      "avg_cpu_usage": 6.3,
      "avg_gpu_memory_used": 18.724761962890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 27,
    "timestamp": 1727305788,
    "tokens_per_second": 537.0519152783212,
    "total_num_tokens": 256
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 2,
      "output_json": "/tmp/tmp.a2LLzKa8Gd",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.5151309911161661,
    "num_requests": 2,
    "output_throughput": 496.9609757807601,
    "requests_per_second": 3.8825076232871885,
    "resource_usage": {
      "avg_cpu_usage": 10.6,
      "avg_gpu_memory_used": 18.723785400390625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 23,
    "timestamp": 1727305812,
    "tokens_per_second": 993.9219515615202,
    "total_num_tokens": 512
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 4,
      "output_json": "/tmp/tmp.snWTKFWv3i",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.5196065008640289,
    "num_requests": 4,
    "output_throughput": 985.3610359928514,
    "requests_per_second": 7.698133093694151,
    "resource_usage": {
      "avg_cpu_usage": 8.3,
      "avg_gpu_memory_used": 18.734527587890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 22,
    "timestamp": 1727305834,
    "tokens_per_second": 1970.7220719857028,
    "total_num_tokens": 1024
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 8,
      "output_json": "/tmp/tmp.z40jyGSxEZ",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.5596355404704809,
    "num_requests": 8,
    "output_throughput": 1829.7622755322718,
    "requests_per_second": 14.295017777595874,
    "resource_usage": {
      "avg_cpu_usage": 4.75,
      "avg_gpu_memory_used": 18.742340087890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 24,
    "timestamp": 1727305858,
    "tokens_per_second": 3659.5245510645436,
    "total_num_tokens": 2048
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 16,
      "output_json": "/tmp/tmp.HfGPDQ47LU",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.6436692103743553,
    "num_requests": 16,
    "output_throughput": 3181.7585290570164,
    "requests_per_second": 24.85748850825794,
    "resource_usage": {
      "avg_cpu_usage": 7.65,
      "avg_gpu_memory_used": 18.760894775390625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 24,
    "timestamp": 1727305882,
    "tokens_per_second": 6363.517058114033,
    "total_num_tokens": 4096
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 32,
      "output_json": "/tmp/tmp.hY0t7A0JRV",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 0.8434718921780586,
    "num_requests": 32,
    "output_throughput": 4856.119140405601,
    "requests_per_second": 37.938430784418756,
    "resource_usage": {
      "avg_cpu_usage": 11.0,
      "avg_gpu_memory_used": 18.798004150390625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 25,
    "timestamp": 1727305907,
    "tokens_per_second": 9712.238280811202,
    "total_num_tokens": 8192
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 64,
      "output_json": "/tmp/tmp.ytpqqwtnOH",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.1775243375450373,
    "num_requests": 64,
    "output_throughput": 6956.968734148713,
    "requests_per_second": 54.35131823553682,
    "resource_usage": {
      "avg_cpu_usage": 9.649999999999999,
      "avg_gpu_memory_used": 18.870269775390625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 26,
    "timestamp": 1727305933,
    "tokens_per_second": 13913.937468297427,
    "total_num_tokens": 16384
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 128,
      "output_json": "/tmp/tmp.1WTvtKNHJc",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 1.937896816059947,
    "num_requests": 128,
    "output_throughput": 8454.5265074078,
    "requests_per_second": 66.05098833912344,
    "resource_usage": {
      "avg_cpu_usage": 7.1,
      "avg_gpu_memory_used": 19.017730712890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 26,
    "timestamp": 1727305959,
    "tokens_per_second": 16909.0530148156,
    "total_num_tokens": 32768
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 256,
      "output_json": "/tmp/tmp.VB496ea4d7",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 3.276184841990471,
    "num_requests": 256,
    "output_throughput": 10001.877665758186,
    "requests_per_second": 78.13966926373583,
    "resource_usage": {
      "avg_cpu_usage": 3.3499999999999996,
      "avg_gpu_memory_used": 19.310699462890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 27,
    "timestamp": 1727305986,
    "tokens_per_second": 20003.75533151637,
    "total_num_tokens": 65536
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 512,
      "output_json": "/tmp/tmp.rvwGCw7OVV",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 6.754910672083497,
    "num_requests": 512,
    "output_throughput": 9701.9787798002,
    "requests_per_second": 75.79670921718906,
    "resource_usage": {
      "avg_cpu_usage": 4.85,
      "avg_gpu_memory_used": 19.310699462890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 30,
    "timestamp": 1727306016,
    "tokens_per_second": 19403.9575596004,
    "total_num_tokens": 131072
  },
  {
    "argumnets_passed": {
      "backend": "vllm",
      "dataset": null,
      "device": "auto",
      "distributed_executor_backend": null,
      "download_dir": null,
      "dtype": "auto",
      "enable_chunked_prefill": false,
      "enable_prefix_caching": false,
      "enforce_eager": false,
      "gpu_memory_utilization": 0.9,
      "input_len": 128,
      "kv_cache_dtype": "auto",
      "load_format": "auto",
      "max_model_len": null,
      "max_num_batched_tokens": null,
      "model": "Qwen/Qwen2-0.5B",
      "n": 1,
      "num_prompts": 1024,
      "output_json": "/tmp/tmp.zrkmL8jWCo",
      "output_len": 128,
      "quantization": null,
      "quantization_param_path": null,
      "seed": 0,
      "tensor_parallel_size": 1,
      "tokenizer": "Qwen/Qwen2-0.5B",
      "trust_remote_code": false,
      "use_beam_search": false
    },
    "elapsed_time": 13.785600928589702,
    "num_requests": 1024,
    "output_throughput": 9507.891652961767,
    "requests_per_second": 74.2804035387638,
    "resource_usage": {
      "avg_cpu_usage": 3.55,
      "avg_gpu_memory_used": 19.310699462890625,
      "avg_gpu_usage": 0.0,
      "total_gpu_memory": 44.98828125
    },
    "run_duration": 37,
    "timestamp": 1727306053,
    "tokens_per_second": 19015.783305923534,
    "total_num_tokens": 262144
  },
  {
    "completion_status": "complete"
  }
]